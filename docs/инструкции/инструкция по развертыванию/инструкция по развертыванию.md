# Инструкция по развертыванию

## Введение

Основой системы является технология контейнеризации Docker. Прикладные программы и програмные модули содержатся внутри образов. После загрузки образа он называется контейнером, внутри контейнера можно выполнять прикладные программы изолированно от базовой операционной системы. Несколько взаимосвязанных контейнеров, обеспечивающих заданную функцию, называются компонентом системы.

Термины:

+ образ - запаковынный набор программных модулей;
+ контейнер - загруженный образ в оперативную память;
+ компонент - один или несколько контейнеров обеспечивающих некоторую функцию системы.

*Компонент СУБД Greenplum*

В основе СУБД Greenplum лежит Posgres. Это реляционая база данных предназначена для хранения небольших (не больших в смысле подхода BigData) таблиц для которых будут выполняться операции вставки, удаления, обновления данных. Компонент рекомендуется использовать для хранения итоговых результатов работы программ, например, множество таблиц метрик, показателей, статистики работы алгоритмов ML.

С документацией можно ознакомиться на сайте:

+ https://www.postgresql.org/docs/15/index.html
+ https://greenplum.org/

Состоит из контейнера (имена контейнеров):

- greenplum


*Компонент разработчика*

Компонент разработчика предназначен для исполнения прикладных программ. Основу компонента составляет программная среда python (https://docs.python.org/3/).

Компонет содержит библиотеки:

+ средства работы с данными
    - pandas
    - pyspark
+ средства визуализации
    - matplotlib
    - shiny
    - jupyter
    - plotnine
    - itables
+ средства мат. моделирования
    - scikit-learn
    - torch
    - transformers
    - catboost
    - tensorflow
    - networkx

Недостающие библиотеки можно установить командой `pip install <имя пакета>`.

Состоит из контейнера (имена контейнеров):

- jupyter

Примечание: В этой версии не подключены опции работы с графическими процессорами.

*Компонент объектное хранилище S3*

Хранилище объектов на основе ключа. При хранении данных объектам назначается уникальный ключ, который может использоваться впоследствии для доступа к данным. Можно воспринимать как обычное файловое хранилище. Может быть использовано для хранения файлов различных форматов, например, json, csv, parquet и т.п. Объектное хранилище совместимо с протоколом "Amazon S3". Используется открытая реализация "Minio" (https://min.io/docs/minio/linux/developers/python/minio-py.html).

 Состоит из контейнера (имена контейнеров):

- minio


*Компонент СУБД in-memory*

Компонент СУБД in-memory предназначен для организации быстрого доступа к данным. Данные постоянно храняться в оперативной памяти. Компонент предназначен для хранения временных данных необходимых в момент выполнения прикладных задач, можно использовать как способ передачи табличных данных между програмными модулями. В компоненте используется реляционная СУБД Tarantool (https://www.tarantool.io/ru/doc/latest/overview/)

Состоит из контейнера (имена контейнеров):

- tarantool

*Компонент управления моделями*

Компонент предназначен для хранения и управления моделями ML. Компонент основан на системе управления MLFlow (https://mlflow.org/docs/latest/index.html). Позволяет записывать статистическую информацию процесса формирования моделей (обучения моделей), предоставляет пользовательский интерфейс для просмотра и анализа. Сохраняемые модели помещаются в объектное хранилище, статистическая информация храниться в СУБД Posgres.

Cостоит из контейнеров (имена контейнеров):

- minio
- postgres-mlflow
- mlflow

*Компонент визуализации*

Компонет использует два разноплановых инструмента визуализации данных, это Superset (https://superset.apache.org/) и Shiny.

Superset - полнофункциональный инструмент для построения графиков и диаграм, в нем применяется принцип визуального программирования.

Shiny - это набор программных библиотек для быстрого построения веб-приложений. Для запуска и отображения приложений используется shiny-сервер.

Cостоит из контейнеров (имена контейнеров):

- postgres-superset
- superset
- shiny

*Компонент СУБД Clickhouse*

В составе компонента колоночная СУБД Clickhouse (https://clickhouse.com/). Компонент предназначен для долгосрочного хранения данных. СУБД Clickhouse не расчитана на удаление и обновление данных, эти операции являются ресурсоемкими и не рекомендуются производителем СУБД. 

Cостоит из контейнера (имена контейнеров):

- clickhouse


*Компонент планировщика*

В качестве планировщика задач используется Apache Airflow (https://airflow.apache.org/). При программировании заданий планировщика используется язык python. Наиболее подробную информоцию о возможностях можно получить из книги "Data Pipelines with Apache Airflow" Bas Harenslak, Julian de Ruiter.

Cостоит из контейнера (имена контейнеров):

- postgres-airflow
- airflow

*Компонент потоковой обработки*

В качестве инструмента потоковой обдаботки данных используется Apache Nifi (https://nifi.apache.org/).

Cостоит из контейнера (имена контейнеров):

- nifi

*Компонент очередь сообщений*

В качестве инструмента хранения очереди сообщения используется Apache Kafka (https://kafka.apache.org/). Для синхронизации метаданных используется Apache ZooKeeper (https://zookeeper.apache.org/). Для просмотра записей используется Offset Explorer (https://www.kafkatool.com/download.html)

Cостоит из контейнера (имена контейнеров):

- kafka
- zookeeper


## Установка и настройка Docker

Скачать и установить Docker [скачать Docker](https://www.docker.com/products/docker-desktop/)

После установки перейти в раздел "Settings" во вкладке "Kubernetes", включить опцию "Enable Kubernetes".

## Запуск компонентов

Требования к ресурсам:

- Минимальные требования: 10 гигабайт (5 гигабайт оперативной памяти требуется для запуска kubernetes без запуска компонент, дополнительно для ОС требуется 4 гигабайта, 1 гигабайт для запуска контейнера);
- Оптимальные требования: 16 гигабайт оперативной памяти.

В первую очередь необходимо определить какие компоненты понадобятся. Рекомендуется, использовать компоненты по мере необходимости, т.к. каждый компонент подребляет некоторое количество ресурсов.

## Установка образов docker

Все необходимые образы скачиваются при первом запуске контейнеров, но можно скачать образы вручную.

Команды скачивания образов для `docker` в `Windows`

```
docker pull aggrik/pyspark:latest
docker pull aggrik/rspark:latest
docker pull aggrik/greenplum_stable:latest
docker pull aggrik/minio:latest
docker pull aggrik/mlflow:latest
docker pull aggrik/postgresql:latest
docker pull aggrik/superset:latest
docker pull aggrik/tarantool:latest
docker pull aggrik/clickhouse:latest
docker pull aggrik/airflow:latest
docker pull aggrik/kafka:latest
docker pull aggrik/zookeeper:latest
docker pull aggrik/nifi:latest
```

Команды скачивания образов для `kubernetes` в `Linux`

```
sudo ctr -n=k8s.io image pull docker.io/aggrik/pyspark:latest
sudo ctr -n=k8s.io image pull docker.io/aggrik/rspark:latest
sudo ctr -n=k8s.io image pull docker.io/aggrik/greenplum_stable:latest
sudo ctr -n=k8s.io image pull docker.io/aggrik/minio:latest
sudo ctr -n=k8s.io image pull docker.io/aggrik/mlflow:latest
sudo ctr -n=k8s.io image pull docker.io/aggrik/postgresql:latest
sudo ctr -n=k8s.io image pull docker.io/aggrik/superset:latest
sudo ctr -n=k8s.io image pull docker.io/aggrik/tarantool:latest
sudo ctr -n=k8s.io image pull docker.io/aggrik/clickhouse:latest
sudo ctr -n=k8s.io image pull docker.io/aggrik/airflow:latest
sudo ctr -n=k8s.io image pull docker.io/aggrik/kafka:latest
sudo ctr -n=k8s.io image pull docker.io/aggrik/nifi:latest
sudo ctr -n=k8s.io image pull docker.io/aggrik/gitbucket:latest
```

Перед тем как запускать контейнеры, потребуется скачать исходные коды этого проекта, для этого установите git. Ссылка на инструкцию https://github.com/git-guides/install-git

Когда git будет установлен, перейдите в пустую папку и клонируйте этот проект при помощи команды `git clone https://github.com/YARIK-AI/ML.git`. Будет создана папка проекта, перейдите в папку. Для просмотра текущего директория и перехода по папкам применяйте команды `ls` и `cd`.

Скрипт запуска всех контейнеров

```
kubectl apply -f ./env/
kubectl apply -f ./greenplum/
kubectl apply -f ./jupyter/
kubectl apply -f ./minio/
kubectl apply -f ./tarantool/
kubectl apply -f ./postgres-mlflow/
kubectl apply -f ./mlflow/
kubectl apply -f ./postgres-superset/
kubectl apply -f ./superset/
kubectl apply -f ./clickhouse/
kubectl apply -f ./postgres-airflow/
kubectl apply -f ./airflow/
kubectl apply -f ./kafka/
kubectl apply -f ./zookeeper/
kubectl apply -f ./gitbucket/
```

# Проверка работоспособности

## Компонент объектное хранилище 

Открыть браузер, пройти по ссылке

```
http://localhost:32010/
login - adminminio
passowrd - adminminio
```

## Компонент разработчика

Открыть браузер, пройти по ссылке

`http://localhost:31188/jupyter/?token=822fce15430e96de9bc18fedf9f938796db4c7927f912028`

## СУБД Clickhouse

Открыть браузер, пройти по ссылке

```
http://localhost:32023/play
login - admin
passowrd - admin
```

Открыть браузер, пройти по ссылке

## Компонент планировщика

Открыть браузер, пройти по ссылке

```
http://localhost:32088
login - admin
passowrd - admin
```

## Компонент потоковой обработки

Открыть браузер, пройти по ссылке

```
http://localhost:31900/nifi
```

## Компонент визуализации

Открыть браузер, пройти по ссылке

```
http://localhost:32699
```

# Перепределение сетевых портов

При необходимости можно переназначить сетевые порты на более привычные для соотвествующих сервисов. При переназначении высокий порт будет также доступен, но добавляется новый из более низкого диапазона. Для выполнения команды требуется запустить `Powershell` с правами администратора.

Проверить наличие открытых портов можно командой 'netstat -an'. Открытые порты будут в статусе `LISTENING`.

Для компонента superset

```
# переназначить порт 32699 на 8088
netsh interface portproxy add v4tov4 protocol=tcp connectaddress=localhost connectport=32699 listenport=8088
# удалить назначение
netsh interface portproxy delete v4tov4 protocol=tcp listenport=8088
```

Для MLflow

```
# переназначить порт 32050 на 5000
netsh interface portproxy add v4tov4 protocol=tcp connectaddress=localhost connectport=32050 listenport=5000
# удалить назначение
netsh interface portproxy delete v4tov4 protocol=tcp listenport=5000
```

Для greenplum

```
# переназначить порт 31832 на 5432
netsh interface portproxy add v4tov4 protocol=tcp connectaddress=localhost connectport=31832 listenport=5432
# удалить назначение
netsh interface portproxy delete v4tov4 protocol=tcp listenport=5432
```

Для jupyter. C jupyter нужно внимательно перенаправлять порт, плагин под vscode может запустить версию jupyter и порт будет уже занят. И наоборот, если понадобится пользоваться встроенным jupyter не забудьте удалить переназначение порта.

```
# переназначить порт 31188 на 8888
netsh interface portproxy add v4tov4 protocol=tcp connectaddress=localhost connectport=31188 listenport=8888
# удалить назначение
netsh interface portproxy delete v4tov4 protocol=tcp listenport=8888
```

Для minio

```
# переназначить порт 32010 на 9001
netsh interface portproxy add v4tov4 protocol=tcp connectaddress=localhost connectport=32010 listenport=9001
netsh interface portproxy add v4tov4 protocol=tcp connectaddress=localhost connectport=32020 listenport=9000
# удалить назначение
netsh interface portproxy delete v4tov4 protocol=tcp listenport=9001
netsh interface portproxy delete v4tov4 protocol=tcp listenport=9000
```

Для clickhouse

```
# переназначить порт 32023 на 8123
netsh interface portproxy add v4tov4 protocol=tcp connectaddress=localhost connectport=32023 listenport=8123
# удалить назначение
netsh interface portproxy delete v4tov4 protocol=tcp listenport=8123
```

Для airflow

```
# переназначить порт 32088 на 8089
netsh interface portproxy add v4tov4 protocol=tcp connectaddress=localhost connectport=32088 listenport=8089
# удалить назначение
netsh interface portproxy delete v4tov4 protocol=tcp listenport=8089
```

Для Kafka

Строка подключения (bootstrap servers) до переназначения:
kubernetes.docker.internal:32041,kubernetes.docker.internal:32042,kubernetes.docker.internal:32043

```
# переназначить внутренние порты kafka на внешние порты 9091, 9092, 9093
netsh interface portproxy add v4tov4 protocol=tcp connectaddress=kubernetes.docker.internal connectport=32031 listenport=9091
netsh interface portproxy add v4tov4 protocol=tcp connectaddress=kubernetes.docker.internal connectport=32032 listenport=9092
netsh interface portproxy add v4tov4 protocol=tcp connectaddress=kubernetes.docker.internal connectport=32033 listenport=9093
# удалить назначение
netsh interface portproxy delete v4tov4 protocol=tcp listenport=9091
netsh interface portproxy delete v4tov4 protocol=tcp listenport=9092
netsh interface portproxy delete v4tov4 protocol=tcp listenport=9093
```

Строка подключения (bootstrap servers) после переназначения: kubernetes.docker.internal:9091,kubernetes.docker.internal:9092,kubernetes.docker.internal:9093

Примечание: в программе "Offset Explorer" выполните "Import Connections..." файла `docs\examples\Offset Explorer\YARIK_connection_backup.xml`.

# Удаление контейнеров

Часть неиспользуемых контейнеров можете удалить.

```
kubectl delete -f ./greenplum/
kubectl delete -f ./jupyter/
kubectl delete -f ./minio/
kubectl delete -f ./tarantool/
kubectl delete -f ./postgres-mlflow/
kubectl delete -f ./mlflow/
kubectl delete -f ./postgres-superset/
kubectl delete -f ./superset/
kubectl delete -f ./clickhouse/
kubectl delete -f ./postgres-airflow/
kubectl delete -f ./airflow/
kubectl delete -f ./kafka/
kubectl delete -f ./zookeeper/
kubectl delete -f ./nifi/
kubectl delete -f ./gitbucket/
```

Удаление образов

```
docker rmi aggrik/pyspark:latest
docker rmi aggrik/rspark:latest
docker rmi aggrik/greenplum_stable:latest
docker rmi aggrik/minio:latest
docker rmi aggrik/mlflow:latest
docker rmi aggrik/postgresql:latest
docker rmi aggrik/superset:2.1.0
docker rmi aggrik/tarantool:latest
docker rmi aggrik/clickhouse:latest
docker rmi aggrik/airflow:latest
docker rmi aggrik/kafka:latest
docker rmi aggrik/zookeeper:latest
docker rmi aggrik/nifi:latest
docker rmi aggrik/gitbucket:latest
```
