{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Примеры заполнения таблицы"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заполенение средствами psycopg2\n",
    "\n",
    "Способ используется при небольших объемах данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подключение к базе данных\n",
    "HOST=os.environ['GREENPLUM_HOST']\n",
    "PORT=os.environ['GREENPLUM_PORT']\n",
    "DATABASE=os.environ['GREENPLUM_DATABASE']\n",
    "SCHEMA = os.environ['GREENPLUM_SCHEMA']\n",
    "LOGIN=os.environ['GREENPLUM_LOGIN']\n",
    "PASSWORD=os.environ['GREENPLUM_PASSWORD']\n",
    "\n",
    "connection = psycopg2.connect( host=HOST, port=PORT, database=DATABASE, user=LOGIN, password=PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# имя таблицы созданной в предыдущих примерах\n",
    "tableName = 'table1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values= [\n",
    "        (1,1.0,'1'),\n",
    "        (2,2.0,'2'),\n",
    "        (3,3.0,'3')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "    insert into {SCHEMA}.{tableName} (c1, c2, c3) values (%s, %s, %s)\n",
    "\"\"\"\n",
    "cur = connection.cursor()\n",
    "cur.executemany(sql,values)\n",
    "connection.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка записанных данных\n",
    "connection = psycopg2.connect( host=HOST, port=PORT, database=DATABASE, user=LOGIN, password=PASSWORD)\n",
    "sql = f\"\"\"\n",
    "     select * FROM {SCHEMA}.{tableName}\n",
    "\"\"\"\n",
    "cur = connection.cursor()\n",
    "cur.execute(sql)\n",
    "data = cur.fetchall()\n",
    "print(data)\n",
    "connection.commit()\n",
    "cur.close()\n",
    "connection.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заполенение средствами spark\n",
    "\n",
    "Используется на больших объемах данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, LongType, StringType, IntegerType, DateType, TimestampType, FloatType\n",
    "from pyspark.sql.functions import col, cast, date_trunc, sum, dayofweek, hour, dayofmonth, lit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# запуск spark\n",
    "spark = SparkSession.builder.appName('fill').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbcURLGreenplum = f'jdbc:postgresql://{HOST}:{PORT}/{DATABASE}?user={LOGIN}&password={PASSWORD}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# формирование dataframe\n",
    "values= [\n",
    "        (4,4.0,'4'),\n",
    "        (5,5.0,'5'),\n",
    "        (6,6.0,'6')\n",
    "    ]\n",
    "\n",
    "schemaData = StructType([ \\\n",
    "    StructField(\"c1\",IntegerType(),True), \n",
    "    StructField(\"c2\",FloatType(),True), \n",
    "    StructField(\"c3\",StringType(),True)\n",
    "  ])\n",
    "\n",
    "df = spark.createDataFrame(values,schema=schemaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# запись в таблицу\n",
    "df.write.format(\"jdbc\").mode(\"append\") \\\n",
    "              .option('url', jdbcURLGreenplum) \\\n",
    "              .option('driver', 'org.postgresql.Driver') \\\n",
    "              .option(\"dbtable\",SCHEMA+'.'+tableName).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение из таблицы\n",
    "query=f'''\n",
    "SELECT  *\n",
    "FROM {SCHEMA}.{tableName}\n",
    "'''\n",
    "df1 = spark.read.format(\"jdbc\") \\\n",
    "              .option('url', jdbcURLGreenplum) \\\n",
    "              .option('driver', 'org.postgresql.Driver') \\\n",
    "              .option('query',query).load()\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
